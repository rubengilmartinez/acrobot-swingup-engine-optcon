% Template for OPTCON-RL course projects - Acrobot Assignment
\documentclass[a4paper,11pt,oneside]{book}

% Use UTF-8 for easy typing of tildes like 'é' and 'ñ'
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb,color}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{float}


\begin{document}
	\pagestyle{myheadings}
	
	%%%%%%%%%%% Cover %%%%%%%%%%%
	\thispagestyle{empty}                                        
	\begin{center}                                                         
		\vspace{5mm}
		{\LARGE UNIVERSIT\`A DI BOLOGNA} \\                       
		\vspace{5mm}
	\end{center}
	\begin{center}
		% Ensure this file exists in a 'figs' folder
		\includegraphics[scale=.27]{figs/logo_unibo}
	\end{center}
	\begin{center}
		\vspace{5mm}
		{\LARGE School of Engineering} \\
		\vspace{3mm}
		{\Large Master Degree in Automation Engineering} \\
		\vspace{20mm}
		{\LARGE Optimal Control and Reinforcement Learning} \\
		\vspace{5mm}{\Large\textbf{OPTIMAL CONTROL OF A GYMNAST ROBOT}}                  
		\vspace{15mm}
	\end{center}
	
	\begin{center}                                                                                
		{\large Professor: \textbf{Giuseppe Notarstefano}} \\        
		\vspace{13mm}
	\end{center}
	
	\begin{center}
		{\large Students:}\\
	\end{center}
	
	\begin{center}
		{\textbf{Rubén Gil Martínez}}\\
	\end{center}
	
	
	
	\begin{center}
		{\textbf{Guillermo López Pérez}}\\
	\end{center}
	
	
	
	\begin{center}
		\vfill
		{\large Academic year 2025/2026} \\
	\end{center}
	
	\newpage
	\thispagestyle{empty}
	
	%%%%%%%%%%% Abstract %%%%%%%%%%%%
	\chapter*{Abstract}
	\thispagestyle{empty}
	This project focuses on the optimal control of a planar gymnast robot, modeled as a double pendulum with torque applied only at the hip (Acrobot). We implement trajectory generation using Newton-like algorithms and tracking via LQR and MPC techniques.
	
	\newpage
	%%%%%%%%%% Lists %%%%%%%%%%
	\tableofcontents 
	\thispagestyle{empty}
	\newpage
	\listoffigures 
	\thispagestyle{empty}
	\newpage
	
	%%%%%%%%%% Introduction %%%%%%%%%%
	\chapter*{Introduction}
	\addcontentsline{toc}{chapter}{Introduction}
	The Acrobot, a planar gymnast robot, serves as a classic benchmark for underactuated mechanical systems. Comprising two links with torque applied solely at the hip joint, it presents a significant control challenge due to its highly non-linear dynamics and the lack of direct actuation at the first joint. 

    The primary objective of this project is to design and implement an optimal control framework capable of driving the system from its stable downward hanging state to the unstable upright equilibrium through a coordinated swing-up maneuver. This involves several integrated technical phases:
    
    \begin{itemize}
        \item \textbf{Task 0: Modeling and Discretization:} Derivation of the system's equations of motion and implementation of the 4th-order Runge-Kutta (RK4) scheme for high-fidelity numeric integration.
        \item \textbf{Task 1 \& 2: Trajectory Generation:} Development of an Iterative Linear Quadratic Regulator (iLQR) algorithm. We explore the impact of reference choice by comparing a naive step reference with a physically-motivated smooth reference that leverages the system's natural frequency to minimize control effort.
        \item \textbf{Task 3: Feedback Tracking via LQR:} Implementation of a Time-Varying LQR controller designed to follow the optimal trajectory while rejecting disturbances and ensuring local stability.
        \item \textbf{Task 4: Predictive Control via MPC:} Implementation of Model Predictive Control (MPC) to enhance tracking performance and robustness by explicitly considering future system behavior.
    \end{itemize}

    By combining trajectory optimization with robust feedback control, we aim to achieve a seamless transitions between equilibria, demonstrating the efficacy of modern optimal control techniques in handling complex robotic dynamics.











	%%%%%%%%%% Tasks %%%%%%%%%%
	
\chapter{Task 0: Problem Setup and Discretization}
\section{System Description}
The Acrobot is a generic planar gymnast robot consisting of two links and two joints. It is a canonical example of an underactuated mechanical system, where control input is only available at the second joint (the "hip"), while the first joint (the "shoulder") is passive.

The state of the system is defined by the generalized coordinates $q = [\theta_1, \theta_2]^\top$, where $\theta_1$ is the angle of the first link with respect to the vertical axis, and $\theta_2$ is the relative angle of the second link with respect to the first. The full state vector is given by $x = [\theta_1, \theta_2, \dot{\theta}_1, \dot{\theta}_2]^\top \in \mathbb{R}^4$. The control input $u = \tau \in \mathbb{R}$ represents the torque applied at the hip joint.

\section{Equations of Motion}
The continuous-time dynamics of the Acrobot are derived using the Euler-Lagrange formalism and can be expressed in the standard manipulator form:
\begin{equation}
    M(q)\ddot{q} + C(q, \dot{q})\dot{q} + F\dot{q} + G(q) = B u
\end{equation}
where:
\begin{itemize}
    \item $M(q) \in \mathbb{R}^{2 \times 2}$ is the symmetric, positive-definite mass matrix.
    \item $C(q, \dot{q}) \in \mathbb{R}^{2 \times 2}$ represents Coriolis and centrifugal forces.
    \item $F \in \mathbb{R}^{2 \times 2}$ is the diagonal matrix of viscous friction coefficients.
    \item $G(q) \in \mathbb{R}^2$ is the gravity vector.
    \item $B = [0, 1]^\top$ is the actuation matrix.
\end{itemize}

For simulation and control design purposes, we solve for the joint accelerations $\ddot{q}$:
\begin{equation}
    \ddot{q} = M(q)^{-1} \left( B u - C(q, \dot{q})\dot{q} - F\dot{q} - G(q) \right)
\end{equation}

\section{Physical Parameters}
The project employs Parameter Set 3, which defines the following physical constants:
\begin{table}[H]
    \centering
    \begin{tabular}{lcl}
        \hline
        Parameter & Symbol & Value \\
        \hline
        Mass of link 1 & $m_1$ & 1.5 kg \\
        Mass of link 2 & $m_2$ & 1.5 kg \\
        Length of link 1 & $l_1$ & 2.0 m \\
        Length of link 2 & $l_2$ & 2.0 m \\
        COM distance link 1 & $l_{c1}$ & 1.0 m \\
        COM distance link 2 & $l_{c2}$ & 1.0 m \\
        Inertia of link 1 & $I_1$ & 2.0 kg$\cdot$m$^2$ \\
        Inertia of link 2 & $I_2$ & 2.0 kg$\cdot$m$^2$ \\
        Gravity & $g$ & 9.81 m/s$^2$ \\
        Viscous friction & $f_1, f_2$ & 1.0 N$\cdot$m$\cdot$s/rad \\
        \hline
    \end{tabular}
    \caption{Acrobot Physical Parameters (Set 3)}
    \label{tab:params}
\end{table}



\section{Discretization via Runge-Kutta 4}
For numerical simulation and discrete-time optimal control, the continuous-time dynamics $\dot{x} = f_c(x, u)$ must be discretized. We employ the 4th-order Runge-Kutta (RK4) integration scheme with a constant sampling period $d_t = 0.01$ s. Given the state at time $t$, the next state $x_{t+1}$ is computed as:
\begin{subequations}
    \begin{align}
        k_1 &= f_c(x_t, u_t) \\
        k_2 &= f_c(x_t + \frac{d_t}{2}k_1, u_t) \\
        k_3 &= f_c(x_t + \frac{d_t}{2}k_2, u_t) \\
        k_4 &= f_c(x_t + d_t k_3, u_t) \\
        x_{t+1} &= x_t + \frac{d_t}{6}(k_1 + 2k_2 + 2k_3 + k_4)
    \end{align}
\end{subequations}
This numeric integration method ensures robust stability and accuracy, facilitating the application of gradient-based optimization algorithms.














\chapter{Task 1 and 2: Trajectory Generation.}
\label{chap:trajectory_generation}

In this chapter, we address the core problem of trajectory generation: finding an optimal control sequence $u(t)$ and state trajectory $x(t)$ that transitions the Acrobot from a stable hanging position to the unstable upright equilibrium. We employ a Newton-type optimal control algorithm (specifically, Differential Dynamic Programming making use of Iterative LQR method) to solve this non-linear optimization problem.

The process is divided into three logical steps: computing the boundary conditions (equilibria), defining a reference trajectory to guide the solver, and executing the iterative optimization loop.




\section{Step 1: Computation of Equilibria}

The first requirement is to rigorously define the start and end points of the maneuver. An equilibrium is defined as a state where the system remains stationary if no external force is applied (or a constant holding torque is maintained). Mathematically, this implies that the acceleration and velocity are zero:
\begin{equation}
    \ddot{q} = 0, \quad \dot{q} = 0 \implies \dot{x} = 0
\end{equation}
We must solve the static equation derived from the dynamics $f(x, u)$:
\begin{equation}
    f(x_{eq}, u_{eq}) = 0
\end{equation}
Given that the gravity vector $G(q)$ and other matrices contain non-linear trigonometric terms ($\sin(\theta_1), \sin(\theta_1 + \theta_2), \sin(\theta_2), \cos(\theta_1), \cos(\theta_2) $), an analytical solution is non-trivial. Therefore, we employ a numerical root-finding algorithm to solve for the configuration angles.

We identified two key equilibria:
\begin{itemize}
    \item \textbf{Stable Equilibrium ($x_{eq1}$):} The "Down" position where the robot hangs vertically under gravity ($x \approx [0, 0, 0, 0]^\top$).
    \item \textbf{Unstable Equilibrium ($x_{eq2}$):} The "Up" position where the robot is balanced perfectly inverted ($x \approx [\pi, 0, 0, 0]^\top$).
\end{itemize}







\section{Step 2: Definition of Reference Curves}

The optimization algorithm requires a reference trajectory $x_{ref}(t)$ to define the cost function. We explored two different approaches to generating this reference, highlighting the impact of physical consistency on solver convergence.

\subsection{Task 1: The Step Reference}
In the first approach, we define a "Step" reference. The time horizon $T$ is split into two halves:
\begin{equation}
    x_{ref}(t) = 
    \begin{cases} 
        x_{eq1} & \text{if } 0 \le t < T/2 \\
        x_{eq2} & \text{if } T/2 \le t \le T 
    \end{cases}
\end{equation}
This reference commands the robot to stay at the bottom for the first half and immediately teleport to the top for the second half.

\textbf{Limitations:} This creates a conflict between the \textit{optimization objective} and the \textit{system physics}. To reach the top, an underactuated robot must swing back and forth ("pump" energy). However, the cost function $J$ penalizes any deviation from zero during the first half. The solver is forced to fight this penalty to discover the necessary swinging motion, often resulting in slower convergence.

\subsection{Task 2: The "Natural" Smooth Reference}
In the second approach, we construct a "Physically Inspired" reference that anticipates the system's dynamics. This reference is composed of two phases:

\begin{enumerate}
    \item \textbf{Phase 1 (Energy Pumping):} We inject sinusoidal oscillations into the reference trajectory. The frequency of these oscillations is tuned to the natural frequency of a single-arm pendulum, approximated by the simplified model $\omega_n \approx \sqrt{g/L_{eff}}$. Where $g$ is the acceleration due to gravity ($g \approx 9.81$ m/s$^2$) and $L_{eff}$ is the effective length of the first part of the pendulum ($L_{eff} \approx L_1$).
    \item \textbf{Phase 2 (Smooth Rise):} We utilize a sigmoid function (logistic curve) to transition smoothly from the oscillating bottom state to the inverted equilibrium, avoiding the infinite derivatives associated with a step change.
\end{enumerate}

\textbf{Advantages for Convergence:} By adding oscillations, we align the cost function with the physics. We effectively signal to the solver: \textit{"It is optimal to swing here."} This reduces the conflict between the objective function and the dynamic constraints, creating a smoother optimization landscape and facilitating faster, more robust convergence.








\section{Step 3: The Optimization Loop (Newton via LQR)}

With the boundary conditions and reference defined, we implement the Newton-type optimal control algorithm. In every iteration $k$, we locally approximate the problem by solving a finite-horizon \textbf{Linear Quadratic Regulator (LQR)} problem to find the optimal control deviation, this sequence of solved subproblems forms the Newton-type update. \cite{Notarstefano2025}.

The process consists of three distinct phases. Below, we detail the mathematical formulation and provide a direct mapping to the variables used in our Python implementation.

\subsection{Phase 1: Forward Pass (Nominal Trajectory)}
We simulate the non-linear dynamics using the current control sequence $\bar{u}$ to generate the nominal trajectory.
\begin{equation}
    \bar{x}_{t+1} = f(\bar{x}_t, \bar{u}_t)
\end{equation}
\textbf{Code Mapping:}
\begin{itemize}
    \item $\bar{x}_t, \bar{u}_t \rightarrow$ \texttt{x\_traj[i]}, \texttt{u[i]}
    \item $f(\cdot) \rightarrow$ \texttt{discrete\_step\_rk4(x, u, dt)}
\end{itemize}

\subsection{Phase 2: Backward Pass (Solving LQR)}
This phase computes the feedback gains and feedforward corrections by propagating the computation of the Riccati difference equations backwards in time.

\subsubsection*{1. Initialization ($t=T$)}
We initialize the Cost-to-Go using the terminal cost Hessian and gradient.
\begin{equation}
    P_T = Q_T, \quad p_T = Q_T(x_T - x_{ref,T})
\end{equation}
\textbf{Code Mapping:}
\begin{itemize}
    \item $P_T \rightarrow$ \texttt{P = self.Q\_final}
    \item $p_T \rightarrow$ \texttt{p = self.Q\_final @ dx\_terminal}
\end{itemize}

\subsubsection*{2. Linearization and Approximation}
For each step $t$, we compute the local derivatives.
\begin{itemize}
    \item Dynamics ($A_t, B_t$): \texttt{A\_t}, \texttt{B\_t} (via \texttt{get\_derivatives\_fd}).
    \item Cost Gradients ($q_t, r_t$): \texttt{q\_t}, \texttt{r\_t} (via \texttt{Q @ dx}, \texttt{R @ du}).
    \item Cost Hessians ($Q_t, R_t$): \texttt{self.Q}, \texttt{self.R}.
\end{itemize}

\subsubsection*{3. The "S" Matrix (auxiliary term)}
To simplify the gain computation, we define the matrix $S_t$, which represents the Hessian of the Action-Value function with respect to the control input $u$.
\begin{equation}
    S_t = R_t + B_t^\top P_{t+1} B_t
\end{equation}
\textbf{Code Mapping:}
\begin{itemize}
    \item $S_t \rightarrow$ \texttt{S\_mat = self.R + B\_t.T @ P @ B\_t}
    \item $S_t^{-1} \rightarrow$ \texttt{S\_inv} (Regularized inverse)
\end{itemize}

\subsubsection*{4. Computing the Gains}
We calculate the optimal \textbf{Feedback Gain} $K_t^*$ and \textbf{Feedforward Correction} $\sigma_t^*$ by minimizing the local quadratic model \cite{Notarstefano2025}:
\begin{align}
    K_t^* &= -S_t^{-1} (B_t^\top P_{t+1} A_t) \\
    \sigma_t^* &= -S_t^{-1} (r_t + B_t^\top p_{t+1})
\end{align}
\textbf{Code Mapping:}
\begin{itemize}
    \item $K_t^* \rightarrow$ \texttt{K\_t} (stored in \texttt{K\_gains})
    \item $\sigma_t^* \rightarrow$ \texttt{sigma\_t} (stored in \texttt{sigma\_vec})
\end{itemize}

\subsubsection*{5. Difference Riccati Equation Update}
Finally, we update the Cost-to-Go parameters ($P_t, p_t$) for the previous time step. In the code, we utilize the computed gains to perform this update efficiently:
\begin{align}
    P_t &= Q_t + A_t^\top P_{t+1} A_t - K_t^{*\top} S_t K_t^* \\
    p_t &= q_t + A_t^\top p_{t+1} - K_t^{*\top} S_t \sigma_t^* \\
    c_t &= 0
\end{align}
\textbf{Code Mapping:}
\begin{itemize}
    \item $K_t^{*\top} S_t K_t^* \rightarrow$ \texttt{term\_quad} (The quadratic reduction)
    \item $K_t^{*\top} S_t \sigma_t^* \rightarrow$ \texttt{term\_lin} (The linear reduction)
    \item $P_t \rightarrow$ \texttt{P} (updated for next loop iteration)
    \item $p_t \rightarrow$ \texttt{p} (updated for next loop iteration)
\end{itemize}

\subsection{Phase 3: Update (Closed-Loop Rollout)}
We generate the new control sequence. Crucially, we employ a \textbf{Closed-Loop} update rule. This means we apply the feedforward correction $\sigma_t^*$ scaled by a step size $\alpha$, plus the feedback reaction to the \textit{actual} state deviation experienced during the new simulation.
\begin{equation}
    u_{new}(t) = \bar{u}_t + \alpha \cdot \sigma_t^* + K_t^* \cdot (x_{new}(t) - \bar{x}_t)
\end{equation}
\textbf{Code Mapping:}
\begin{itemize}
    \item $\alpha \rightarrow$ \texttt{alpha} (Determined via Armijo Line Search)
    \item $x_{new}(t) - \bar{x}_t \rightarrow$ \texttt{dx\_deviation}
    \item Update $\rightarrow$ \texttt{u\_new[i] = u[i] + du}
\end{itemize}
The feedback term $K_t^*$ stabilizes the unstable Acrobot dynamics during the rollout, ensuring that the new trajectory remains valid even when moving far from the equilibrium.
















\chapter{Task 3: Trajectory Tracking via LQR}

\section{Linearization around the Optimal Generated Trajectory}
The optimal trajectory $(x^*_t, u^*_t)$ generated in the previous chapter serves as the nominal path. To handle disturbances and model uncertainties, we linearize the discrete-time dynamics $x_{t+1} = f_d(x_t, u_t)$ around this nominal trajectory at each time step. This produces a time-varying linear approximation of the system that is locally valid for small deviations from the reference trajectory:
\begin{equation}
    \delta x_{t+1} \approx A_t^{\text{traj}} \delta x_t + B_t^{\text{traj}} \delta u_t
\end{equation}
where $\delta x_t = x_t - x^*_t$, $\delta u_t = u_t - u^*_t$, and the Jacobian matrices are defined as:
\begin{equation}
    A_t^{\text{traj}} = \frac{\partial f_d}{\partial x} \Big|_{x^*_t, u^*_t}, \quad B_t^{\text{traj}} = \frac{\partial f_d}{\partial u} \Big|_{x^*_t, u^*_t}
\end{equation}
These Jacobians are computed numerically using finite differences to account for the complexity of the RK4 integration.

\section{Discrete-Time Finite-Horizon TV-LQR Optimization}
The core of the tracking problem is formulated as an optimization task over a finite time horizon $T$. Given the nominal trajectory $(x^*_t, u^*_t)$, we define the tracking error states $\delta x_t = x_t - x^*_t$ and control deviations $\delta u_t = u_t - u^*_t$. The goal is to find an optimal sequence of control deviations that minimizes a quadratic cost function:
\begin{equation}
    \sum_{t=0}^{T-1} (\delta x_t^\top Q_{\text{reg}} \delta x_t + \delta u_t^\top R_{\text{reg}} \delta u_t) + \delta x_T^\top Q_{\text{final}} \delta x_T
\end{equation}
subject to the linearized dynamics $\delta x_{t+1} = A_t^\text{traj} \delta x_t + B_t^\text{traj} \delta u_t$.

\quad

The solution to this problem is obtained via dynamic programming, specifically by solving the discrete-time Riccati difference equations backwards in time. This process yields a sequence of optimal cost-to-go matrices $P_t$, which are used to compute the feedback gains.

\section{Implementation of the Time-Varying Feedback Controller}
A crucial aspect of our implementation is the separation between the optimization phase (computing gains) and the control phase (applying the feedback law).

\subsection{Phase 1: Computation of Optimal Feedback Gains}
Before starting the tracking experiment, we perform a backward pass from $t = T$ down to $t = 0$. In this phase, we pre-compute and store the optimal feedback gains $K_t$ for every time step:
\begin{subequations}
    \begin{align}
        P_T &= Q_{\text{final}} \\
        K^{\text{reg}}_t &= (R_{\text{reg}} + B_t^{\text{traj, T}} P_{t+1} B_t^{\text{traj}})^{-1} (B_t^{\text{traj, T}} P_{t+1} A_t^{\text{traj}}) \\
        P_t &= Q_{\text{reg}} + A_t^{\text{traj}, T}P_{t+1} A_t^{\text{traj}} - (A_t^{\text{traj}, T}P_{t+1} B_t^{\text{traj}}) K^{\text{reg}}_t
    \end{align}
\end{subequations}
This pre-computation ensures that the controller can operate in real-time during the forward simulation, as the heavy matrix operations are already solved.

\subsection{Phase 2: State Feedback Control Law}
Once the gains $K_t$ are available, the physical system (or the high-fidelity RK4 simulator) is controlled using a combination of feedforward and feedback terms. At each sampling instant $t$, the controller measures the actual state $x_t$, computes the error $\delta x_t$, and applies the following control command:
\begin{equation}
    u_t = u^{traj}_t - K^{reg}_t (x_t - x^{traj}_t), \quad t=0,\ldots,T-1
\end{equation}
Here, $u^{traj}_t$ acts as the \textit{feedforward} nominal torque required to maintain the ideal trajectory, while the term $- K_t \delta x_t$ provides the \textit{feedback} corrective action. This dual structure allows the Acrobot to stay close to the optimized swing-up path even when faced with initial condition perturbations or unmodeled dynamics, leveraging the local optimality of the LQR design.
	











\chapter{Task 4: Trajectory Tracking via MPC}

This chapter discusses the implementation of Model Predictive Control (MPC) to track the optimal reference, accounting for system constraints and performance.
	




\chapter{Task 5: Animation and Results}
\label{chap:results}

In this chapter, we present the numerical results for all tasks, including trajectory generation performance and tracking effectiveness under various conditions.

\section{Task 1: Trajectory Generation (Step Reference)}
\label{sec:task1_results}
Performance metrics for the iLQR algorithm using a simple step reference.
\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.50\textwidth]{figs/output_task1_opt_des_traj.png} & \includegraphics[width=0.50\textwidth]{figs/output_task1_intermediate.png} \\
        (a) Optimal vs Desired Trajectories & (b) Intermediate Trajectories \\[2ex]
        \includegraphics[width=0.50\textwidth]{figs/output_task1_norm_descent.png} & \includegraphics[width=0.50\textwidth]{figs/output_task1_cost_evolution.png} \\
        (c) Norm of Descent (Semi-Log) & (d) Cost Evolution (Semi-Log)
    \end{tabular}
    \caption{Task 1: Trajectories and Convergence Metrics.}
    \label{fig:task1_convergence}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.50\textwidth]{figs/output_task1_1.png} & \includegraphics[width=0.50\textwidth]{figs/output_task1_2.png} \\
        (a) Armijo Landscape (Iter 0) & (b) Armijo Landscape (Iter 1) \\[2ex]
        \includegraphics[width=0.50\textwidth]{figs/output_task1_3.png} & \includegraphics[width=0.50\textwidth]{figs/output_task1_6.png} \\
        (c) Armijo Landscape (Iter 10) & (d) Armijo Landscape (Iter 40)
    \end{tabular}
    \caption{Task 1: Armijo Landscapes across iterations.}
    \label{fig:task1_armijo}
\end{figure}



\section{Task 2: Trajectory Generation (Smooth Reference)}
\label{sec:task2_results}
Comparison of the iLQR performance when initiated with a physically-inspired smooth reference.
\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.50\textwidth]{figs/output_task2_opt_des_traj.png} & \includegraphics[width=0.50\textwidth]{figs/output_task2_intermediate.png} \\
        (a) Optimal vs Desired Trajectories & (b) Intermediate Trajectories \\[2ex]
        \includegraphics[width=0.50\textwidth]{figs/output_task2_norm_descent.png} & \includegraphics[width=0.50\textwidth]{figs/output_task2_cost_evolution.png} \\
        (c) Norm of Descent (Semi-Log) & (d) Cost Evolution (Semi-Log)
    \end{tabular}
    \caption{Task 2: Trajectories and Convergence Metrics.}
    \label{fig:task2_convergence}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.50\textwidth]{figs/output_task2_1.png} & \includegraphics[width=0.50\textwidth]{figs/output_task2_2.png} \\
        (a) Armijo Landscape (Iter 0) & (b) Armijo Landscape (Iter 1) \\[2ex]
        \includegraphics[width=0.50\textwidth]{figs/output_task2_3.png} & \includegraphics[width=0.50\textwidth]{figs/output_task2_6.png} \\
        (c) Armijo Landscape (Iter 10) & (d) Armijo Landscape (Iter 40)
    \end{tabular}
    \caption{Task 2: Armijo Landscapes across iterations.}
    \label{fig:task2_armijo}
\end{figure}



\newpage
\section{Task 3: LQR Tracking Performance}
\label{sec:task3_results}
Tracking capability of the Time-Varying LQR controller under different initial condition perturbations.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/output_task3_1.png} \\
    (a) System Trajectory vs Desired Optimal Trajectory
    \caption{Task 3: System Trajectory vs Desired Optimal Trajectory.}
    \label{fig:task3_trajectory}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tabular}{cc}
        \includegraphics[width=0.55\textwidth]{figs/output_task3_2.png} & \includegraphics[width=0.55\textwidth]{figs/output_task3_3.png} \\
        (b) Tracking Error ([0.5, -0.3, 0, 0]) & (c) Tracking Error ([0, 0, 0.5, -0.5]) \\[3ex]
    \end{tabular}
    
    \begin{tabular}{c}
        \includegraphics[width=0.55\textwidth]{figs/output_task3_4.png} \\
        (d) Tracking Error ([-0.2, 0.2, 0.1, -0.1])
    \end{tabular}
    \caption{Task 3: LQR Tracking Errors for different initial condition perturbations.}
    \label{fig:task3_errors}
\end{figure}

% Task 4 results omitted as per user request (plots not available).

\section{Animation}
	%%%%%%%%%% Conclusions %%%%%%%%%%
	\chapter*{Conclusions}
	\addcontentsline{toc}{chapter}{Conclusions} 
	% Summary of findings
	
	%%%%%%%%%% Bibliography %%%%%%%%%%%
	% Ensure bibfile.bib exists or use biblatex
	\addcontentsline{toc}{chapter}{Bibliography}
	\bibliographystyle{plain}
	\bibliography{bibfile}
	
\end{document}